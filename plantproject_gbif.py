# -*- coding: utf-8 -*-
"""PlantProject_GBIF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f27QBrLoEA4zMe3K35agHw73gwqoCGpU
"""

import requests
import pandas as pd

def get_species_occurrences(species_name):
    storage = []
    url = 'https://api.gbif.org/v1/occurrence/search'
    params = {
        'scientificName': species_name,
        #'limit': 10  # adjust the limit as needed
    }

    response = requests.get(url, params=params)
    data = response.json()
    occurrences = data.get('results', [])
    for occurrence in occurrences:
        species = occurrence.get('scientificName')
        latitude = occurrence.get('decimalLatitude')
        longitude = occurrence.get('decimalLongitude')
        storage.append([species,latitude,longitude])

    return storage

def gbif_api_extracter(df): #diff name
  storage = []
  for name in df["Species name"].tolist():
    storage.append(get_species_occurrences(name))
  return storage

def build_pandas_df_from_matrix(api_extractor_list):
  storage_df = []
  for i in api_extractor_list:
    storage_df.append(pd.DataFrame(i,columns = ["Species name", "latitude","longitude"]))
  return storage_df

def process_data(path):
  plant_df = df = pd.read_csv(path, encoding='latin1')
  gbif_list_of_lists = gbif_api_extracter(plant_df)
  dfs = build_pandas_df_from_matrix(gbif_list_of_lists)
  return pd.concat(dfs, axis=0)

def main(path):
  df = process_data(path)
  final_df = pd.concat(dfs, axis=0).dropna()
  #final_df.to_csv() // SUPPLY OUTPUT PATH

# df = pd.read_csv("./list_exceptional_status_filtered.csv", encoding='latin1')
main("./list_exceptional_status_filtered.csv")